{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi\n",
        "!pip install colabcode"
      ],
      "metadata": {
        "id": "P6F-gsH19Sgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/font-recognition-model/\""
      ],
      "metadata": {
        "id": "o5SV27Y8vQ8g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(path)"
      ],
      "metadata": {
        "id": "xfv8YoAEvx_y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from colabcode import ColabCode\n",
        "from pydantic import BaseModel\n",
        "from pydantic import Field\n",
        "from font_recognition import Preprocessing, PyTorchClassifier"
      ],
      "metadata": {
        "id": "dyVysiJlvLOU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2gSxMRDMrnaQ4xVXeGvAbLFnehh_2tWjPGWBhHFVRkYJzBgwm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXueB_uMv7Ts",
        "outputId": "40035252-56eb-4c38-d432-24370969daf0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohsKp9o382y-"
      },
      "outputs": [],
      "source": [
        "app = FastAPI()\n",
        "\n",
        "# Labels\n",
        "labels = ['Scheherazade New', 'Marhey', 'Lemonada', 'IBM Plex Sans Arabic']\n",
        "\n",
        "# Load the preprocessor pipeline\n",
        "with open(f\"{path}preprocess_pipe.pkl\", \"rb\") as f:\n",
        "    loaded_pipeline = pickle.load(f)\n",
        "\n",
        "# Initialize the preprocessor\n",
        "preprocessor = Preprocessing(loaded_pipeline)\n",
        "\n",
        "# Initialize the pytorch model\n",
        "pytorch_classifier = PyTorchClassifier(2981, 512, 256, 4 , learning_rate=0.00025, epoch=50)\n",
        "pytorch_classifier.load_state_dict(torch.load(f\"{path}best_model.pth\"))\n",
        "pytorch_classifier.eval()\n",
        "\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_items():\n",
        "    return \"Welcome to the Font Recognition API\"\n",
        "\n",
        "# Input Schema is an image file\n",
        "class Image(BaseModel):\n",
        "    file: UploadFile = File(..., title=\"Image file to be uploaded\")\n",
        "\n",
        "# Output Schema\n",
        "class Prediction(BaseModel):\n",
        "    pred : str = Field(..., title=\"Font Prediction\", example=\"Lemonada\")\n",
        "\n",
        "@app.post(\"/predict_font\", response_model=Prediction)\n",
        "async def predict_font(file: UploadFile = File(...)):\n",
        "    try:\n",
        "        # Read the image file using cv2 and convert to grayscale\n",
        "        contents = await file.read()\n",
        "        image = cv2.imdecode(np.frombuffer(contents, np.uint8), cv2.IMREAD_GRAYSCALE)\n",
        "        # Preprocess the image\n",
        "        image = preprocessor.preprocess_test_data(image)\n",
        "        # Predict the font\n",
        "        pred = pytorch_classifier.predict(image)\n",
        "        print(pred)\n",
        "        return {\"pred\": labels[pred[0]]}\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "server = ColabCode(port=8000, code=False)\n",
        "server.run_app(app=app)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zed68c3Q9kL2",
        "outputId": "6cda2b41-37cc-4c0f-963a-36238b7b8cc2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [1221]\n",
            "INFO:uvicorn.error:Started server process [1221]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:uvicorn.error:Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:uvicorn.error:Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
            "INFO:uvicorn.error:Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://37b5-35-203-166-189.ngrok-free.app\" -> \"http://localhost:8000\"\n",
            "INFO:     102.186.233.105:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     102.186.233.105:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     102.186.233.105:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 14.80it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n",
            "INFO:     102.186.233.105:0 - \"POST /predict_font HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 23.55it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  6.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n",
            "INFO:     102.186.233.105:0 - \"POST /predict_font HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 24.71it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  5.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2]\n",
            "INFO:     102.186.233.105:0 - \"POST /predict_font HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 12.38it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3]\n",
            "INFO:     102.186.233.105:0 - \"POST /predict_font HTTP/1.1\" 200 OK\n",
            "INFO:     102.186.233.105:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     102.186.233.105:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 15.64it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3]\n",
            "INFO:     102.186.233.105:0 - \"POST /predict_font HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:uvicorn.error:Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:uvicorn.error:Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:uvicorn.error:Application shutdown complete.\n",
            "INFO:     Finished server process [1221]\n",
            "INFO:uvicorn.error:Finished server process [1221]\n"
          ]
        }
      ]
    }
  ]
}