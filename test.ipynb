{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as im\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import rotate\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score,f1_score,classification_report\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ 'Scheherazade New' , 'Marhey' , 'Lemonada' , 'IBM Plex Sans Arabic']\n",
    "image_size = 600\n",
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        plt.axis('off')\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images from fonts-dataset folder\n",
    "def load_images():\n",
    "    # Load the images from the fonts-dataset folder\n",
    "    images_train = []\n",
    "    labels_train = []\n",
    "    filenames = []\n",
    "    empty_images_filenames = [\"360.jpeg\",\"627.jpeg\",\"853.jpeg\"] \n",
    "    # Use tqdm to show a progress bar\n",
    "    for i in tqdm(labels):\n",
    "        for filename in os.listdir(f'fonts-dataset/{i}'):\n",
    "            img = cv2.imread(f'fonts-dataset/{i}/{filename}', cv2.IMREAD_GRAYSCALE)\n",
    "            # img = cv2.resize(img, (image_size, image_size))\n",
    "            if i == \"Lemonada\" and filename in empty_images_filenames:\n",
    "                print(filename)\n",
    "                print(\"empty image\")\n",
    "                continue\n",
    "            images_train.append(img)\n",
    "            labels_train.append(i)\n",
    "            filenames.append(filename)\n",
    "    return images_train, labels_train,filenames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:15<00:15,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360.jpeg\n",
      "empty image\n",
      "627.jpeg\n",
      "empty image\n",
      "853.jpeg\n",
      "empty image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:29<00:00,  7.46s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load the images\n",
    "X_train, y_train_org, filenames = load_images()\n",
    "# Change the y_train to numbers\n",
    "y_train_org = [labels.index(i) for i in y_train_org]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_score(arr, angle):\n",
    "    \"\"\"\n",
    "    Find the score of the skew angle to be used in deskewing the image\n",
    "    \n",
    "    Args:\n",
    "    arr: the image array\n",
    "    angle: the angle to rotate the image by\n",
    "    \n",
    "    Returns:\n",
    "    hist: the histogram of the image\n",
    "    score: the score of the skew angle\n",
    "    \"\"\"\n",
    "    \n",
    "    # mode{‘reflect’, ‘grid-mirror’, ‘constant’, ‘grid-constant’, ‘nearest’, ‘mirror’, ‘grid-wrap’, ‘wrap’}\n",
    "    data = rotate(arr, angle, reshape=False, order=0, mode='constant', cval=0, prefilter=False)\n",
    "    hist = np.sum(data, axis=1)\n",
    "    score = np.sum((hist[1:] - hist[:-1]) ** 2)\n",
    "    return hist, score\n",
    "\n",
    "def rotate_image(image, angle):\n",
    "    \"\"\"\n",
    "    Rotates an image by a given angle and fills the remaining pixels with white color.\n",
    "\n",
    "    Args:\n",
    "        image: A NumPy array representing the input image.\n",
    "        angle: The rotation angle in degrees.\n",
    "\n",
    "    Returns:\n",
    "        A new NumPy array representing the rotated image.\n",
    "    \"\"\"\n",
    "    # Get image height and width\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Compute the rotation matrix\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((width / 2, height / 2), angle, 1)\n",
    "\n",
    "    # Perform the rotation and fill the remaining pixels with white color\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(1, 1, 1))\n",
    "\n",
    "    return rotated_image\n",
    "\n",
    "def deskew(binary_img):\n",
    "    \"\"\"\n",
    "    Deskew the image\n",
    "    \n",
    "    Args:\n",
    "    binary_img: the binary image\n",
    "    \n",
    "    Returns:\n",
    "    pix: the deskewed image\n",
    "    \"\"\"\n",
    "    bin_img = (binary_img // 255.0)\n",
    "    # angles to check for skew angle = 45 degrees and 90 degrees and 180\n",
    "    angles = np.array ([0 , 45 , 90 , 135 , 180 , 225 , 270 , 315])\n",
    "    scores = []\n",
    "    for angle in angles:\n",
    "        hist, score = find_score(bin_img, angle)\n",
    "        scores.append(score)\n",
    "\n",
    "    best_score = max(scores)\n",
    "    best_angle = angles[scores.index(best_score)]\n",
    "    # print('Best angle: {}'.format(best_angle))\n",
    "\n",
    "    # correct skew\n",
    "    # data = rotate(bin_img, best_angle, reshape=False, order=0)\n",
    "    data = rotate_image(bin_img, best_angle)\n",
    "    img = im.fromarray((255 * data).astype(\"uint8\"))\n",
    "\n",
    "    pix = np.array(img)\n",
    "    return pix\n",
    "\n",
    "def preprocess(img):\n",
    "    \"\"\"\n",
    "    Preprocess the image\n",
    "    \n",
    "    Args:\n",
    "    img: the image\n",
    "    \n",
    "    Returns:\n",
    "    img: the preprocessed image\n",
    "    \"\"\"\n",
    "    sharpen_kernel = np.array([[0,-1, 0], [-1,5,-1], [0,-1,0]])\n",
    "    img = cv2.medianBlur(img, 3) # To remove Salt and Pepper noise\n",
    "    img = cv2.filter2D(img, -1, sharpen_kernel)  # Sharpen the image\n",
    "    img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1] # Convert the image to binary\n",
    "    deskewed_img = deskew(img) # Deskew the image\n",
    "    final_img = cv2.bitwise_not(deskewed_img) if np.mean(deskewed_img) > 127 else deskewed_img # Invert the image if the mean is less than 127 \n",
    "    final_img = cv2.resize(final_img, (image_size, image_size)) # Resize the image\n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Load pipeline\n",
    "pipeline = joblib.load('pipeline.pkl')\n",
    "\n",
    "# Load the pytorch_model.pth\n",
    "model_state_dict = torch.load('best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "class PyTorchClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim , learning_rate=0.0002 , epoch=15):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "        self.output_dim = output_dim\n",
    "        self.best_accuracy = -1  # Initialize with a value that will definitely be improved upon\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoch = epoch\n",
    "        self.model = self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim1, self.hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim2, self.output_dim),\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        lb = LabelBinarizer()\n",
    "        y_train_one_hot = lb.fit_transform(y_train)\n",
    "        # y_val_one_hot = lb.fit_transform(y_val)\n",
    "\n",
    "        X_train_tensor = torch.FloatTensor(X_train)\n",
    "        y_train_tensor = torch.LongTensor(y_train_one_hot)\n",
    "\n",
    "        # X_val_tensor = torch.FloatTensor(X_val)\n",
    "        # y_val_tensor = torch.LongTensor(y_val_one_hot)\n",
    "        \n",
    "        # Create a dataset\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        # test_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "        # Create a dataloader\n",
    "        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "        # test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr= self.learning_rate)\n",
    "\n",
    "        # Create a tqdm object\n",
    "        progress_bar = tqdm(range(self.epoch), desc=\"Training\", leave=False)\n",
    "\n",
    "        for epoch in progress_bar:\n",
    "            total_loss = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(X_batch)\n",
    "                loss = criterion(outputs, torch.max(y_batch, 1)[1])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy on the validation set\n",
    "            # val_outputs = self.model(X_val_tensor)\n",
    "            # val_predictions = torch.max(val_outputs, 1)[1]\n",
    "            # accuracy = (val_predictions == torch.max(y_val_tensor, 1)[1]).sum().item() / len(y_val_tensor)\n",
    "            \n",
    "            accuracy = accuracy_score(y_train, self.predict(X_train))\n",
    "\n",
    "            # If the current model has better accuracy, save the model parameters\n",
    "            # if accuracy > self.best_accuracy:\n",
    "            #     self.best_accuracy = accuracy\n",
    "            #     self.best_model_params = self.model.state_dict()\n",
    "\n",
    "            # Update the progress bar\n",
    "            progress_bar.set_postfix({'Loss': f'{total_loss:.4f}', 'Accuracy': f'{accuracy:.4f}'})\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_tensor = torch.FloatTensor(X)\n",
    "        with torch.no_grad():\n",
    "            # Set the best_model_params to the model\n",
    "            predictions = self.model(X_tensor)\n",
    "        _, predicted = torch.max(predictions, 1)\n",
    "        return predicted.numpy()\n",
    "\n",
    "    def save_best_model(self, filepath):\n",
    "        torch.save(self.best_model_params, filepath)\n",
    "        \n",
    "    def load_model(self, model_state_dict):\n",
    "        self.model.load_state_dict(model_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "def forward(img):\n",
    "    \"\"\"\n",
    "    Forward the image through the pipeline\n",
    "    \n",
    "    Args:\n",
    "    img: the image\n",
    "    \n",
    "    Returns:\n",
    "    pred: the prediction of the image\n",
    "    \"\"\"\n",
    "    img = preprocess(img)\n",
    "    # Get HOG features\n",
    "    hog_features = hog(img,orientations= 16, pixels_per_cell=(32, 32), cells_per_block=(4, 4), block_norm= 'L2-Hys')\n",
    "    hog_features = np.array(hog_features)\n",
    "    \n",
    "    # Get SIFT features\n",
    "    sift_obj = cv2.SIFT_create()\n",
    "    kp, des = sift_obj.detectAndCompute(img, None)\n",
    "    if des is None:\n",
    "        # Add a row of zeros to the SIFT descriptors\n",
    "        des = np.zeros((1, 128))\n",
    "    des = des.flatten()\n",
    "    \n",
    "    fixed_length = 128 * 350\n",
    "    # If the length of the SIFT descriptors is less than 128 * 350, pad the descriptors with zeros to make the length 128 * 350 , if it is greater than 128 * 350, truncate the descriptors to make the length 128 * 350\n",
    "    if len(des) < fixed_length:\n",
    "        padded_des = np.zeros(fixed_length - len(des))\n",
    "        des = np.concatenate((des, padded_des))\n",
    "    else:\n",
    "        des = des[:fixed_length]\n",
    "    padded_des = des\n",
    "    \n",
    "    padded_des = np.array(padded_des)\n",
    "    features = np.concatenate((hog_features, padded_des))\n",
    "    # Apply pipeline\n",
    "    features = pipeline.transform([features])\n",
    "    # Initialize the model\n",
    "    model = PyTorchClassifier(input_dim=features.shape[1], hidden_dim1=512, hidden_dim2=256, output_dim=4)\n",
    "    # Create the model\n",
    "    model.create_model()\n",
    "    # Load the model\n",
    "    model.load_model(model_state_dict)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Predict the image\n",
    "    pred = model.predict(features)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random batch of images\n",
    "\n",
    "def get_random_batch(X_train, y_train, batch_size=200):\n",
    "    \"\"\"\n",
    "    Get a random batch of images\n",
    "    \n",
    "    Args:\n",
    "    X_train: the images\n",
    "    y_train: the labels\n",
    "    batch_size: the batch size\n",
    "    \n",
    "    Returns:\n",
    "    X_batch: the batch of images\n",
    "    y_batch: the batch of labels\n",
    "    \"\"\"\n",
    "    indices = np.random.choice(len(X_train), batch_size)\n",
    "    X_batch = [X_train[i] for i in indices]\n",
    "    y_batch = [y_train[i] for i in indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use get_random_batch to get a batch of images\n",
    "X_batch, y_batch = get_random_batch(X_train, y_train_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:13<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n",
      "Number of wrong predictions: 0\n",
      "Number of correct predictions: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Count all the wrong predictions\n",
    "wrong_predictions = 0\n",
    "# Count the number of images\n",
    "num_images = 0\n",
    "# Count the number of correct predictions\n",
    "correct_predictions = 0\n",
    "\n",
    "# Loop through all the images\n",
    "for i in tqdm(range(len(X_batch))):\n",
    "    # Get the prediction of the image\n",
    "    pred = forward(X_batch[i])\n",
    "    # Get the actual label of the image\n",
    "    actual_label = y_batch[i]\n",
    "    # Increment the number of images\n",
    "    num_images += 1\n",
    "    # If the prediction is correct, increment the number of correct predictions\n",
    "    if pred == actual_label:\n",
    "        correct_predictions += 1\n",
    "    # If the prediction is wrong, increment the number of wrong predictions\n",
    "    else:\n",
    "        wrong_predictions += 1\n",
    "        \n",
    "# Print the accuracy\n",
    "print(f'Accuracy: {correct_predictions / num_images * 100}%')\n",
    "\n",
    "# Print the number of wrong predictions\n",
    "print(f'Number of wrong predictions: {wrong_predictions}')\n",
    "\n",
    "# Print the number of correct predictions\n",
    "print(f'Number of correct predictions: {correct_predictions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:12<00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time taken to preprocess an image and make a prediction: 0.6602267432212829 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the time taken to preprocess an image and make a prediction try it on the X_batch and take average time\n",
    "import time\n",
    "times = []\n",
    "for i in tqdm(range(len(X_batch))):\n",
    "    start = time.time()\n",
    "    forward(X_batch[i])\n",
    "    end = time.time()\n",
    "    times.append(end - start)\n",
    "    \n",
    "# Calculate the average time\n",
    "average_time = np.mean(times)\n",
    "print(f'Average time taken to preprocess an image and make a prediction: {average_time} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
